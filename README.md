# ğŸ“Š Data Warehouse and Anlaytics Project
End-to-end project showcasing data warehousing, ETL pipelines, and analytics using **PostgreSQL** and the **Medallion Architecture**.

---
## ğŸ—ï¸ Data Architecture
This project follows Medallion Architecture, with distinct **Bronze**, **Silver** and **Gold** layers:

![Data Architecture](docs/data_architecture.png)

1. ğŸ¥‰ **Bronse**: Stores the raw data as-is from the source system. Data is ingested from CSV files into Postgresql database.
2. ğŸ¥ˆ **Silver**: This layer includes data cleansing, standardization and normalization processes to prepare data for the analysis.
3. ğŸ¥‡ **Gold**: Business-Ready Model into star schema required for reporting and analytics.

---
## ğŸš§ Project Overview
This project involves:

1. **Data Architecture**: Modern layered architecture using Bronze, Silver, and Gold zones. layers.
2. **ETL Pipelines**: Extract, transform, and load (ETL) operations across the layers.
3. **Data Modeling**: Creating dimension and fact tables following the star schema.
4. **Analytics & Reporting**: Creating SQL-based reports and dashboards for actionable insights.

ğŸ¯ Great for showcasing skills in:
- SQL Development
- Data Architect
- Data Engineering  
- ETL Pipeline Developer  
- Data Modeling  
- Data Analytics
---
## ğŸš€ Project Requirements

#### ğŸ¯ Objective
Design a modern data warehouse using PostgreSQL to consolidate CRM and ERP data for analytical reporting and data-driven decision-making.

#### ğŸ“‹ Specifications
- **Data Sources**: Two source systems (ERP and CRM) as CSV files.
- **Data Quality**: Perform thorough cleansing and normalization.
- **Integration**: Merge sources into a unified analytical model.
- **Scope**: Focus on the latest data (no historization).
- **Documentation**: Provide accessible, well-documented data models for business and technical stakeholders.

---
## ğŸ“ Repository Structure
```
data_warehouse_project/
â”‚
â”œâ”€â”€ datasets/                           # Raw source data (ERP & CRM CSVs)
â”‚
â”œâ”€â”€ docs/                               # Documentation and diagrams
â”‚   â”œâ”€â”€ data_architecture.pdf           # Project architecture overview
â”‚   â”œâ”€â”€ data_catalog.md                 # Field-level metadata and descriptions
â”‚   â”œâ”€â”€ data_flow.pdf                   # Data flow across layers
â”‚   â”œâ”€â”€ data_model.pdf                  # Star schema and table relationships
â”‚   â”œâ”€â”€ data_integration.pdf            # Table joins and integration logic
â”‚   â”œâ”€â”€ naming-conventions.md           # Naming conventions and standards
â”‚
â”œâ”€â”€ scripts/                            # SQL scripts for all layers
â”‚   â”œâ”€â”€ bronze/                         # Raw data ingestion
â”‚   â”œâ”€â”€ silver/                         # Cleaning and transformation logic
â”‚   â”œâ”€â”€ gold/                           # Analytical models (facts & dimensions)
â”‚
â”œâ”€â”€ tests/                              # Data quality checks and validation scripts
â”‚
â”œâ”€â”€ README.md                           # Project overview (this file)
â”œâ”€â”€ LICENSE                             # Licensing information
â”œâ”€â”€ .gitignore                          # Files/directories to ignore in Git
â””â”€â”€ requirements.txt                    # Environment and tooling dependencies

```

---
## ğŸ› ï¸ Tools & Tech Stack:
- **Postgresql:** Relational database engine 
- **Git Repository:** Version control and code collaboration
- **DrawIO:** Diagrams for architecture, flow, and data models
- **Notion:** Project documentation and task management
- **Datasets:** Source data for ERP and CRM systems

---
## âš™ï¸ Project Setup
#### ğŸ“¦ Python Dependencies
This project uses a few Python libraries to automate PostgreSQL schema and table creation:
- `psycopg2-binary` â€“ Connects Python to PostgreSQL
- `python-dotenv` â€“ Loads `.env` variables like DB credentials securely
Install them using:
```bash

  pip install -r requirements.txt

```
And be sure to define a .env in config folder like:
```env
DB_HOST=localhost
DB_PORT=5432
DB_USER=my_user
DB_PASSWORD=my_password
DEFAULT_DB=my_database
```
---
## ğŸ“š What I Learned
- Practical implementation of **Medallion Architecture**.
- Building **ETL pipelines** in SQL.
- Designing and documenting a **star schema**.
- Cleaning and transforming messy real-world data.
- Using Git for version control in data projects.
---
## ğŸ¥ Conclusion
This project illustrates how to build a scalable, maintainable, and well-documented data warehouse using PostgreSQL and SQL. It's designed as a portfolio-worthy project for showcasing expertise in **data engineering**, **data modeling**, and **analytics**.
